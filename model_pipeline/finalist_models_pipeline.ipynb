{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwmrATlaNhtLxzIyBefxMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablosierrafernandez/FarmacoDB/blob/main/model_pipeline/finalist_models_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objetivo\n",
        "Proporcionar un modelo para la predicción de la **Vida Media** utilizando descriptores moleculares.\n",
        "Usted podrá usar el parámetro farmacocinético que desee. Simplemente reemplace el `.csv` correspondiente al parámetro.\n",
        "\n",
        "La finalidad principal consiste en ofrecer un pipeline para poder aplicar a la estimación de otros parámetros farmacocinéticos contemplados en la base de datos, facilitando así una herramienta valiosa en el campo de la farmacocinética y la farmacología personalizada.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bICX1r3qdBOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Índice:\n",
        "1.   Importación de bibliotecas\n",
        "2.   Limpieza de datos\n",
        "3.   Construcción de modelos\n",
        "4.   Modelo a producción\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XQ9zCyYKdn5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importación de bibliotecas"
      ],
      "metadata": {
        "id": "3aPrWDM1eX-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "6qHsY3MnebEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Carga del conjunto de datos"
      ],
      "metadata": {
        "id": "9tSKBa1_ermF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/MyDrive/halflife.csv')  # Reemplaza 'tu_archivo.csv' con el nombre de tu archivo\n"
      ],
      "metadata": {
        "id": "-zE8DeAneqnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Limpieza de datos\n"
      ],
      "metadata": {
        "id": "Z6Dy_Uw4erIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se han realizado diversas operaciones de limpieza de datos, incluyendo eliminación de valores faltantes, columnas no numéricas, y valores atípicos."
      ],
      "metadata": {
        "id": "o6kGxaZ0fHSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Limpieza"
      ],
      "metadata": {
        "id": "wFCy2_q0gurW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifica las columnas no numéricas\n",
        "non_numeric_columns = []\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        non_numeric_columns.append(column)\n",
        "\n",
        "# Elimina las columnas no numéricas\n",
        "data = data.drop(columns=non_numeric_columns)\n",
        "# Muestra las columnas no numéricas\n",
        "print(\"Columnas no numéricas:\")\n",
        "print(non_numeric_columns)\n",
        "\n",
        "# Número de filas antes de eliminar\n",
        "num_filas_antes = len(data)\n",
        "\n",
        "# Elimina las filas con valores faltantes\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Número de filas después de eliminar\n",
        "num_filas_despues = len(data)\n",
        "\n",
        "# Muestra los resultados\n",
        "print(\"Número de filas antes de eliminar:\", num_filas_antes)\n",
        "print(\"Número de filas después de eliminar:\", num_filas_despues)\n",
        "# Seleccionar columnas con valores booleanos\n",
        "bool_columns = data.select_dtypes(include=['bool']).columns\n",
        "print(bool_columns)\n",
        "# Eliminar las columnas con valores booleanos\n",
        "data = data.drop(columns=bool_columns)\n",
        "# Reemplazar los valores NaN con 0.0\n",
        "data = data.fillna(0.0)\n",
        "\n",
        "# Eliminar columnas que contienen solo valores 0.0\n",
        "data = data.loc[:, (data != 0.0).any(axis=0)]"
      ],
      "metadata": {
        "id": "7bVlDZOjfrr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Outliers (opcional)"
      ],
      "metadata": {
        "id": "QLS41VCFg1w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = data['median'].values\n",
        "ax = sns.boxplot(x)\n",
        "\n",
        "print('The meadian is: ', data['median'].median())"
      ],
      "metadata": {
        "id": "vd3dc7G4gCBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notas:\n",
        "# La línea representa la mediana\n",
        "# El cuadro en el medio muestra el comienzo del Q1 (percentil 25) y el final del Q3 (percentil 75)\n",
        "# Las líneas (izquierda - derecha) muestran el cuartil mínimo y el cuartil máximo\n",
        "# Los puntos en la derecha son \"valores atípicos\"\n"
      ],
      "metadata": {
        "id": "9xKa4cd_fuAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si nota que quedan muchos valores atípicos aplique el siguiente codigo para eliminar outliers."
      ],
      "metadata": {
        "id": "pjzKvikygYuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calcula el primer y tercer cuartil\n",
        "Q1 = data['median'].quantile(0.25)\n",
        "Q3 = data['median'].quantile(0.75)\n",
        "\n",
        "# Calcula el rango intercuartílico (IQR)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define los límites superior e inferior para identificar outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtra los datos para eliminar los outliers\n",
        "data = data[(data['median'] >= lower_bound) & (data['median'] <= upper_bound)]\n"
      ],
      "metadata": {
        "id": "QNa6hDMbgjY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Selección de características"
      ],
      "metadata": {
        "id": "VLOaRwf7hR3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puede aplicar otro método de selección de características que considere. En este caso se aplica 'Backward Elimination'"
      ],
      "metadata": {
        "id": "396E3SFRhVtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "cols = list(X.columns)\n",
        "pmax = 1\n",
        "while (len(cols)>0):\n",
        "    p= []\n",
        "    X_1 = X[cols]\n",
        "    X_1 = sm.add_constant(X_1)\n",
        "    model = sm.OLS(y,X_1).fit()\n",
        "    p = pd.Series(model.pvalues.values[1:],index = cols)\n",
        "    pmax = max(p)\n",
        "    feature_with_p_max = p.idxmax()\n",
        "    if(pmax>0.05):\n",
        "        cols.remove(feature_with_p_max)\n",
        "    else:\n",
        "        break\n",
        "selected_features_BE = cols\n",
        "print(selected_features_BE)"
      ],
      "metadata": {
        "id": "UIqiaVabhfpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[selected_features_BE]\n",
        "\n",
        "y = data[\"median\"]  # Columna objetivo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qtG7C8oEhpd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Test y Train"
      ],
      "metadata": {
        "id": "cJoiIyryhyYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "División del conjunto de datos en entrenamiento y prueba"
      ],
      "metadata": {
        "id": "OmqF6txVis5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "X = X.values.astype(np.float64)\n",
        "y = y.values.astype(np.float64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "nrMk_TlHh3UF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## 2.5. Normalización y estandarización"
      ],
      "metadata": {
        "id": "GTGzOgqnh-R1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elija el metodo de normalización y/o estandarización deseado a aplicar a la salida y/o entrada de los datos del modelo."
      ],
      "metadata": {
        "id": "bPZywdxXiISt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_scaler = StandardScaler() #MinMaxScaler(), StandardScaler(), None\n",
        "output_scaler = StandardScaler()#MinMaxScaler(), StandardScaler(), None\n",
        "\n",
        "if input_scaler is not None:\n",
        "    input_scaler.fit(X_train)\n",
        "    X_train = input_scaler.transform(X_train)\n",
        "    X_test = input_scaler.transform(X_test)\n",
        "if output_scaler is not None:\n",
        "    y_train = y_train.reshape(len(y_train), 1)\n",
        "    y_test = y_test.reshape(len(y_test), 1)\n",
        "    output_scaler.fit(y_train)\n",
        "    y_train = output_scaler.transform(y_train)\n",
        "    y_test = output_scaler.transform(y_test)"
      ],
      "metadata": {
        "id": "WLS9RPLRiSnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Construcción de modelos"
      ],
      "metadata": {
        "id": "89BHkOV-idE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se procede a la construcción y entrenamiento de modelos predictivos."
      ],
      "metadata": {
        "id": "hAlcXD78jbRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Red Neuronal Artificial (ANN)"
      ],
      "metadata": {
        "id": "jjhTfurrjgMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1. Entrenamiento"
      ],
      "metadata": {
        "id": "-VVWGgkfkfut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición del modelo\n",
        "def build_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ])\n",
        "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "nk_IEdljjk2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento del modelo\n",
        "model = build_model()\n",
        "model.fit(X_train, y_train, epochs=1000, verbose=1)\n"
      ],
      "metadata": {
        "id": "aoRgEAuhjmjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2. Visualización"
      ],
      "metadata": {
        "id": "SjFxrm8Bkno9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = output_scaler.inverse_transform(y_train)\n",
        "y_test = output_scaler.inverse_transform(y_test)\n",
        "y_pred = output_scaler.inverse_transform(model.predict(X_test))\n",
        "trainpreds = output_scaler.inverse_transform(model.predict(X_train))\n",
        "X_train=output_scaler.inverse_transform(X_train)\n",
        "X_test=output_scaler.inverse_transform(X_test)\n",
        "model.evaluate(X_train,y_train)\n",
        "model.evaluate(X_test,y_test)\n",
        "print(\"-------------\")\n",
        "print(\"MAE - TEST:\",metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"MAE - TRAIN:\",metrics.mean_absolute_error(y_train, trainpreds))\n",
        "print(\"MSE:\",metrics.mean_squared_error(y_test,y_pred))\n",
        "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "print(\"-------------\")\n",
        "y_real = np.array(y_test[:50])\n",
        "y_predd = np.array(y_pred[:50])\n",
        "indices = np.arange(len(y_real))\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(indices, y_real, marker='o', label='Real', linestyle='-')\n",
        "plt.plot(indices, y_predd, marker='o', label='Predicción', linestyle='--')\n",
        "plt.xlabel('Muestras')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Comparación entre Valores Reales y Predicciones')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "y_real = np.array(y_test[:5])\n",
        "y_predd = np.array(y_pred[:5])\n",
        "indices = np.arange(len(y_real))\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(indices, y_real, marker='o', label='Real', linestyle='-')\n",
        "plt.plot(indices, y_predd, marker='o', label='Predicción', linestyle='--')\n",
        "plt.xlabel('Muestras')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Comparación entre Valores Reales y Predicciones')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "# scatterplot of actual vs. pred\n",
        "fig, axes = plt.subplots(1,2)\n",
        "axes[0].scatter(x=y_train, y=model.predict(X_train))\n",
        "axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[0].set_title(\"Training\")\n",
        "x = np.linspace(*axes[0].get_xlim())\n",
        "axes[0].plot(x, x, color='red')\n",
        "axes[1].scatter(x=y_test, y=model.predict(X_test))\n",
        "axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[1].set_title(\"Validation\")\n",
        "x = np.linspace(*axes[1].get_xlim())\n",
        "axes[1].plot(x, x, color='red')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sOUF_04TjuRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 MLJAR"
      ],
      "metadata": {
        "id": "OhyDW_KFyJaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi"
      ],
      "metadata": {
        "id": "K7VkUO5lyQvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido"
      ],
      "metadata": {
        "id": "VdGwAPLhySio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uvicorn"
      ],
      "metadata": {
        "id": "rUSHG1oqyT6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-multipart"
      ],
      "metadata": {
        "id": "Ea0Ml7NyyVGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mljar-supervised"
      ],
      "metadata": {
        "id": "RTWtOjCyyWLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.0.0"
      ],
      "metadata": {
        "id": "ecP9XgXdyYKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape(-1)  # Convierte en un vector 1D"
      ],
      "metadata": {
        "id": "amsag4UOyZOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Entrenamiento"
      ],
      "metadata": {
        "id": "3BVzFOvfyiko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from supervised.automl import AutoML # mljar-supervised\n",
        "\n",
        "\n",
        "\n",
        "automl = AutoML(mode=\"Compete\" , total_time_limit=900)\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "predictions = automl.predict(X_test)\n",
        "print(\"Test MSE:\", mean_squared_error(y_test, predictions))\n",
        "model = automl\n",
        "y_train = y_train.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "T_BEyqh3ylyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Visualización"
      ],
      "metadata": {
        "id": "h7VZtl1Pysln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = output_scaler.inverse_transform(y_train)\n",
        "y_test = output_scaler.inverse_transform(y_test)\n",
        "y_pred = output_scaler.inverse_transform(model.predict(X_test).reshape(-1, 1))\n",
        "trainpreds = output_scaler.inverse_transform(model.predict(X_train).reshape(-1, 1))\n",
        "X_train=output_scaler.inverse_transform(X_train)\n",
        "X_test=output_scaler.inverse_transform(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "print(\"MAE - TEST:\",metrics.mean_absolute_error(y_test,y_pred))\n",
        "print(\"MAE - TRAIN:\",metrics.mean_absolute_error(y_train, trainpreds))\n",
        "print(\"-------------\")\n",
        "print (\"MSE:\",metrics.mean_squared_error(y_test,y_pred))\n",
        "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,y_pred)))\n",
        "# Valores reales\n",
        "y_real = np.array(y_test[:50])\n",
        "\n",
        "# Predicciones\n",
        "y_predd = np.array(y_pred[:50])\n",
        "# Crear un array con los índices para etiquetar los puntos en el gráfico\n",
        "indices = np.arange(len(y_real))\n",
        "\n",
        "# Crear una figura y ejes\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(indices, y_real, marker='o', label='Real', linestyle='-')\n",
        "plt.plot(indices, y_predd, marker='o', label='Predicción', linestyle='--')\n",
        "\n",
        "# Etiquetas y título del gráfico\n",
        "plt.xlabel('Muestras')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Comparación entre Valores Reales y Predicciones')\n",
        "\n",
        "# Mostrar una leyenda\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n",
        "# scatterplot of actual vs. pred\n",
        "\n",
        "fig, axes = plt.subplots(1,2)\n",
        "\n",
        "\n",
        "axes[0].scatter(x=y_train, y=model.predict(X_train))\n",
        "axes[0].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[0].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[0].set_title(\"Training\")\n",
        "\n",
        "x = np.linspace(*axes[0].get_xlim())\n",
        "axes[0].plot(x, x, color='red')\n",
        "\n",
        "axes[1].scatter(x=y_test, y=model.predict(X_test))\n",
        "axes[1].set_xlabel(\"Actual\", fontsize=10)\n",
        "axes[1].set_ylabel(\"Predicted\",  fontsize=10)\n",
        "axes[1].set_title(\"Validation\")\n",
        "\n",
        "x = np.linspace(*axes[1].get_xlim())\n",
        "axes[1].plot(x, x, color='red')\n",
        "\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "_=plt.plot(y_test,y_test,color='orange')"
      ],
      "metadata": {
        "id": "-q3H-s0HyrtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Modelo a producción"
      ],
      "metadata": {
        "id": "IzI_WWNE07og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Guardar modelo"
      ],
      "metadata": {
        "id": "KO05H5gF1Miw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save(\"mi_modelo.h5\")\n"
      ],
      "metadata": {
        "id": "yvdaPCwv1EFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Cargar modelo"
      ],
      "metadata": {
        "id": "PLUcKmB31TYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "modelo_cargado = load_model(\"mi_modelo.h5\")\n"
      ],
      "metadata": {
        "id": "b_f3mSvl1LNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}